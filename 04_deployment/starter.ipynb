{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "mlopsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "cells": [
  {
   "id": "c0dbc843",
   "cell_type": "markdown",
   "source": "### \ud83d\ude95 Ride Duration Prediction \u2013 Batch Mode\n\nIn this notebook, I apply a pre-trained ride duration model to perform batch predictions on NYC Yellow Taxi data. The dataset used is from **March 2023**.  \nThe prediction results are stored locally and can be optionally uploaded to cloud storage for further processing.\n",
   "metadata": {}
  },
  {
   "id": "9da9f988",
   "cell_type": "markdown",
   "source": "#### \ud83d\udd27 Environment Check",
   "metadata": {}
  },
  {
   "id": "d4bcfa25",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "!pip freeze | findstr scikit-learn\n!python -V",
   "outputs": []
  },
  {
   "id": "c6fa9db5",
   "cell_type": "markdown",
   "source": "#### \ud83d\udce6 Load Model and Preprocessing Tools",
   "metadata": {}
  },
  {
   "id": "98c39bfc",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "import pickle\nimport pandas as pd\n\n# Load model and DictVectorizer\nwith open('model.bin', 'rb') as f_in:\n    dv, model = pickle.load(f_in)",
   "outputs": []
  },
  {
   "id": "e8aec188",
   "cell_type": "markdown",
   "source": "#### \ud83e\uddfc Read & Prepare Input Data",
   "metadata": {}
  },
  {
   "id": "240819d3",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "categorical = ['PULocationID', 'DOLocationID']\n\ndef read_data(filename):\n    df = pd.read_parquet(filename)\n\n    # Calculate trip duration in minutes\n    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n    df['duration'] = df.duration.dt.total_seconds() / 60\n\n    # Filter trips with duration between 1 and 60 minutes\n    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n\n    # Prepare categorical features\n    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n\n    return df",
   "outputs": []
  },
  {
   "id": "1a4d5e80",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# Load March 2023 trip data\ndf = read_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet')",
   "outputs": []
  },
  {
   "id": "4b295ba9",
   "cell_type": "markdown",
   "source": "#### \ud83e\uddee Generate Predictions",
   "metadata": {}
  },
  {
   "id": "4d7ac1ee",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "dicts = df[categorical].to_dict(orient='records')\nX_val = dv.transform(dicts)\ny_pred = model.predict(X_val)",
   "outputs": []
  },
  {
   "id": "c9475f28",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# Check standard deviation of predicted durations\nround(y_pred.std(), 3)",
   "outputs": []
  },
  {
   "id": "2c4be235",
   "cell_type": "markdown",
   "source": "#### \ud83c\udd94 Add Ride ID",
   "metadata": {}
  },
  {
   "id": "8128c58b",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "df['ride_id'] = (\n    df['tpep_pickup_datetime'].dt.year.astype(str).str.zfill(4) + '/' +\n    df['tpep_pickup_datetime'].dt.month.astype(str).str.zfill(2) + '_' +\n    df.index.astype(str)\n)\ndf['ride_id'].head()",
   "outputs": []
  },
  {
   "id": "5362b512",
   "cell_type": "markdown",
   "source": "#### \ud83d\udcbe Save Predictions to Parquet",
   "metadata": {}
  },
  {
   "id": "c2449d4e",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "df_result = df[[\"ride_id\"]].copy()\ndf_result['duration'] = y_pred\n\noutput_file = \"output/result.parquet\"\ndf_result.to_parquet(\n    output_file,\n    engine='pyarrow',\n    compression=None,\n    index=False\n)",
   "outputs": []
  },
  {
   "id": "6e96e753",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "import os\n\nsize_bytes = os.path.getsize(output_file)\nsize_mb = size_bytes / (1024 * 1024)\n\nprint(f\"File size: {size_bytes:,} bytes ({size_mb:.2f} MB)\")",
   "outputs": []
  }
 ]
}
